{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced dimensionality reduction techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates advanced dimensionality reduction techniques such as Principal Component Analysis (PCA), Multi-Dimensional Scaling (MDS), and t-Distributed Stochastic Neighbor Embedding (t-SNE) on both image and text datasets. The project provides a hands-on exploration of how these techniques can be used to reduce high-dimensional data into lower-dimensional spaces while preserving meaningful patterns and structures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outline\n",
    "\n",
    "In this notebook we will:\n",
    "* Explain the following advanced dimensionality reduction techniques:\n",
    "    * Principal component analysis\n",
    "    * Multi-dimensional scaling\n",
    "    * t-SNE\n",
    "* Implement these techniques on an image dataset.\n",
    "* Implement these techniques on a text dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimensionality reduction on images\n",
    "This notebook will provide a high-level overview of some of the more advanced techniques for dimensionality reduction. We will be using the [handwritten digits data set](http://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits), which is a collection of images of handwritten digits between 0 and 9. The data was generated by a total of 43 people, who wrote a total of 5620 digits by hand which were then digitised and processed into 8x8 greyscale images.\n",
    "\n",
    "We'll start by importing the necessary packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "import numpy as np\n",
    "from sklearn import (manifold, datasets, decomposition, ensemble,\n",
    "                     discriminant_analysis, random_projection, preprocessing)\n",
    "from matplotlib import offsetbox\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "sns.set(style='whitegrid', palette='muted',\n",
    "        rc={'figure.figsize': (15,10)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading and inspecting the data\n",
    "The digits dataset is included as part of the `sklearn` library, which means loading it into the notebook is a breeze. For this train, we will simplify things by only looking at the first six digits in the dataset. We can use the `n_class` argument in the `load_digits()` function to select only the numbers from 0 to 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = datasets.load_digits(n_class=6)\n",
    "X = digits.data\n",
    "y = digits.target\n",
    "n_samples, n_features = X.shape\n",
    "\n",
    "print(\"Total number of samples: \", n_samples)\n",
    "print(\"Features per sample: \", n_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, the image shows a selection from the 64-dimensional digits dataset. Each digit is represented as an 8x8 array of pixels, with values ranging between 0 (white) and 16 (black)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axs = plt.subplots(nrows=10, ncols=10, figsize=(6, 6))\n",
    "for idx, ax in enumerate(axs.ravel()):\n",
    "    ax.imshow(X[idx].reshape((8, 8)), cmap=plt.cm.binary)\n",
    "    ax.axis(\"off\")\n",
    "_ = fig.suptitle(\"A selection from the 64-dimensional digits dataset\", fontsize=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same concept applies to our dataset, only the arrays have been strung out into single rows of 64 values, ranging between 0 and 16. Let's take a look at the first digit in the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Could you tell that the first array was a zero? Unless you are some sort of savant genius, you probably wouldn't be able to tell which digit is represented by looking only at the array values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dimensionality reduction techniques\n",
    "Now what we are going to try and do is reduce the dimensionality of the entire dataset to just two dimensions (down from 64 dimensions â€“ one per pixel). We will use a few different dimensionality reduction techniques, and at each stage, we will plot the data and see how it is distributed in these two dimensions.   \n",
    "\n",
    "What is very important to note here is that none of these algorithms will be shown the labels of the data; they will be entirely unsupervised. In each case, we will plot the data in two dimensions, but include the known labels of the data points in the plots for our own validation.   \n",
    "\n",
    "For plotting, we are going to use the same `plot_embedding()` function defined in the original `sklearn` example code. This does a fantastic job of plotting the digits in a two-dimensional space, so there is no need to reinvent the wheel here.   \n",
    "\n",
    "**Note:** You will see the word **\"embedding\"** used in some of the comments and plots below. Simply put, an embedding is a representation of a vector in a different feature space. So in this case, the original digits exist as 64-dimensional arrays and are then reduced to just two dimensions. The resulting two-dimensional vectors are referred to as the embedding vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale and visualise the embedding vectors\n",
    "def plot_embedding(X, title=None):\n",
    "    \n",
    "    # normalise data\n",
    "    x_min, x_max = np.min(X, 0), np.max(X, 0)\n",
    "    X = (X - x_min) / (x_max - x_min)\n",
    "\n",
    "    plt.figure()\n",
    "    \n",
    "    ax = plt.subplot(111)\n",
    "    \n",
    "    for i in range(X.shape[0]):\n",
    "        plt.text(X[i, 0], X[i, 1], str(y[i]),\n",
    "                 color=plt.cm.Set1(y[i] / 10.),\n",
    "                 fontdict={'weight': 'bold', 'size': 9})\n",
    "\n",
    "    if hasattr(offsetbox, 'AnnotationBbox'):\n",
    "        # only print thumbnails with matplotlib > 1.0\n",
    "        shown_images = np.array([[1., 1.]])  # just something big\n",
    "        for i in range(X.shape[0]):\n",
    "            dist = np.sum((X[i] - shown_images) ** 2, 1)\n",
    "            if np.min(dist) < 4e-3:\n",
    "                # don't show points that are too close\n",
    "                continue\n",
    "            shown_images = np.r_[shown_images, [X[i]]]\n",
    "            imagebox = offsetbox.AnnotationBbox(\n",
    "                offsetbox.OffsetImage(digits.images[i], cmap=plt.cm.gray_r),\n",
    "                X[i])\n",
    "            ax.add_artist(imagebox)\n",
    "    plt.xticks([]), plt.yticks([])\n",
    "    if title is not None:\n",
    "        plt.title(title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Principal component analysis (PCA)\n",
    "The objective of PCA is to decompose a dataset into mutually orthogonal components that **each maximise the variance in the dataset**.   \n",
    "\n",
    "We will use PCA to decompose the dataset into the first two principal components, which will contain the largest and second-largest amounts of variance, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Computing PCA projection\")\n",
    "t0 = time()\n",
    "X_pca = decomposition.PCA(n_components=2).fit_transform(X)\n",
    "t1 = time()\n",
    "print(\"Finished PCA projection in \" + str(t1-t0) + \"s.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, before using the awesome `plot_embedding()` function, let's plot the data, without labels, in the first two principal components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.scatterplot(x=X_pca[:,0], y=X_pca[:,1],\n",
    "                     sizes=(10, 200))\n",
    "plt.xlabel(\"PC1\")\n",
    "plt.ylabel(\"PC2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you spot any obvious clusters? Perhaps one or two on the right side of the plot?   \n",
    "\n",
    "Now, let's plot the data with labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_embedding(X_pca,\n",
    "               \"Principal Components projection of the digits (time %.2fs)\" %\n",
    "               (t1 - t0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we can see that digits do seem to group together, but there isn't the clearest separation between the different digits.   \n",
    "\n",
    "Now, let's take a look at some other techniques and see how they perform.   \n",
    "\n",
    "### Multi-dimensional scaling (MDS)\n",
    "The goal of MDS is to map features to a low-dimensional space **while preserving the distances** between observations in a given dataset.   \n",
    "\n",
    "MDS can be performed using algorithms that are either *metric* or *non-metric*. Non-metric approaches are typically used to preserve ordinality (order) within data. This is more of a necessity when there are categorical features present in the data. Since the data used here is entirely numeric, we will use a metric approach.   \n",
    "\n",
    "The **stress** is a measure of the degree to which distances between points in the original feature space correspond with the distances in the low-dimensional space. A lower stress value is preferred, and it is this quantity that is minimised by MDS.\n",
    "\n",
    "For more information on MDS, read the [`sklearn` user guide](https://scikit-learn.org/stable/modules/manifold.html#multidimensional-scaling)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Computing MDS embedding\")\n",
    "clf = manifold.MDS(n_components=2, \n",
    "                   n_init=4, \n",
    "                   max_iter=200,\n",
    "                   n_jobs=-1,\n",
    "                   random_state=42,\n",
    "                   dissimilarity='euclidean')\n",
    "t0 = time()\n",
    "X_mds = clf.fit_transform(X)\n",
    "t1 = time()\n",
    "print(\"Done. Time: %f\" % (t1-t0))\n",
    "print(\"Stress: %f\" % clf.stress_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_embedding(X_mds,\n",
    "               \"MDS embedding of the digits (time %.2fs)\" %\n",
    "               (t1 - t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "here we can see that the separation of the clusters is similar to `PCA` and you can't tell which one is better, so let's continue and try one more technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Data_Science",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
